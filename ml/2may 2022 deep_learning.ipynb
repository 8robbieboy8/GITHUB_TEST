{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "bat = 128\n",
    "num = 10\n",
    "epochs = 20\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spaceastonomy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, num)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu', input_shape= (784,)))\n",
    "model.add(tf.keras.layers.Dense(num, activation='relu'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "sgd = tf.keras.optimizers.SGD(lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0574 - accuracy: 0.5962\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0454 - accuracy: 0.7028\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0432 - accuracy: 0.7185\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0418 - accuracy: 0.7270\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0390 - accuracy: 0.7562\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0328 - accuracy: 0.8187\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0317 - accuracy: 0.8270\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0310 - accuracy: 0.8320\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0303 - accuracy: 0.8361\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0298 - accuracy: 0.8398\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0294 - accuracy: 0.8425\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0290 - accuracy: 0.8448\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0287 - accuracy: 0.8475\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0284 - accuracy: 0.8493\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 4s 10ms/step - loss: 0.0281 - accuracy: 0.8511\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0278 - accuracy: 0.8525\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0276 - accuracy: 0.8538\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 4s 10ms/step - loss: 0.0274 - accuracy: 0.8547\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0272 - accuracy: 0.8560\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0270 - accuracy: 0.8573\n",
      "테스트 손실값: 0.027634920552372932\n",
      "테스트 정확도: 0.8517000079154968\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy']) \n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=bat, epochs=epochs) \n",
    "\n",
    "# 학습을 평가한다. \n",
    "score = model.evaluate(X_test, y_test, verbose=0) \n",
    "print('테스트 손실값:', score[0]) \n",
    "print('테스트 정확도:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - 1s 3ms/step - loss: 0.6482 - accuracy: 0.8128\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.8468\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.8511\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.8489\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.8532\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8532\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.8511\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8489\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8489\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.8489\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.8489\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.8532\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.8532\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.8319\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.8255\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.8447\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.8383\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.8468\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.8511\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.8511\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.8532\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.8511\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.8532\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8489\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8511\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.8532\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8383\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8532\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.8532\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8511\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.8511\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8553\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.8532\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8489\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8489\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8532\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.8511\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.8489\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.8319\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8574\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8511\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.8447\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8511\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4032 - accuracy: 0.8511\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8532\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8532\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8447\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8532\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8511\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8511\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8532\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8553\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4128 - accuracy: 0.8489\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8468\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.8532\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3921 - accuracy: 0.8532\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8532\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.8574\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8532\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8574\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8553\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.8468\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8532\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.8511\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3902 - accuracy: 0.8553\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.8511\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8489\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8511\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8511\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.8574\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8511\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8340\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8532\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3907 - accuracy: 0.8553\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8553\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8553\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8426\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8553\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8426\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8468\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8532\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8489\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3944 - accuracy: 0.8532\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.8468\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8489\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3922 - accuracy: 0.8489\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8511\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8468\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8468\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3965 - accuracy: 0.8596\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8532\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.8489\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3953 - accuracy: 0.8511\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8489\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8574\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.8426\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8447\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8596\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4051 - accuracy: 0.8532\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3832 - accuracy: 0.8468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x224de4e1900>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 딥러닝을 구동하는 데 필요한 케라스 함수를 불러옴\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# 필요한 라이브러리를 불러옴\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분.\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "# 준비된 수술 환자 데이터를 불러들임.\n",
    "Data_set = np.loadtxt(\"./ThoraricSurgery.csv\", delimiter=\",\")\n",
    "\n",
    "# 환자의 기록과 수술 경과를 X와 Y로 구분하여 저장함.\n",
    "X = Data_set[:, 0:17]\n",
    "Y = Data_set[:,17]\n",
    "\n",
    "# 딥러닝 구조를 결정함(모델을 설정하고 실행하는 부분).\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=17, activation=\"relu\"))   # 노드 30 개 은닉층\n",
    "model.add(Dense(1, activation=\"sigmoid\"))               # 노드 1 개 출력층\n",
    "\n",
    "# 딥러닝을 실행\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer = \"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X, Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05738835781812668,\n",
       " 0.045441556721925735,\n",
       " 0.04319344460964203,\n",
       " 0.04184938594698906,\n",
       " 0.03897925093770027,\n",
       " 0.032808490097522736,\n",
       " 0.0317198745906353,\n",
       " 0.030954768881201744,\n",
       " 0.030339233577251434,\n",
       " 0.02982558310031891,\n",
       " 0.029379723593592644,\n",
       " 0.02899847738444805,\n",
       " 0.028664249926805496,\n",
       " 0.028360145166516304,\n",
       " 0.028087068349123,\n",
       " 0.027834810316562653,\n",
       " 0.02760821208357811,\n",
       " 0.027399452403187752,\n",
       " 0.027195613831281662,\n",
       " 0.02702329121530056]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5961666703224182,\n",
       " 0.7027666568756104,\n",
       " 0.7185333371162415,\n",
       " 0.7270166873931885,\n",
       " 0.7562000155448914,\n",
       " 0.8186666369438171,\n",
       " 0.8269500136375427,\n",
       " 0.8320000171661377,\n",
       " 0.8361499905586243,\n",
       " 0.839816689491272,\n",
       " 0.8425166606903076,\n",
       " 0.8448166847229004,\n",
       " 0.8474500179290771,\n",
       " 0.8492666482925415,\n",
       " 0.8510500192642212,\n",
       " 0.852483332157135,\n",
       " 0.8538333177566528,\n",
       " 0.8547000288963318,\n",
       " 0.855983316898346,\n",
       " 0.8573333621025085]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], marker = '*' )\n",
    "plt.plot(history.history['accuracy'], marker = 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>plasma</th>\n",
       "      <th>pressure</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnant  plasma  pressure  thickness  insulin   BMI  pedigree  age  \\\n",
       "0           6     148        72         35        0  33.6     0.627   50   \n",
       "1           1      85        66         29        0  26.6     0.351   31   \n",
       "2           8     183        64          0        0  23.3     0.672   32   \n",
       "3           1      89        66         23       94  28.1     0.167   21   \n",
       "4           0     137        40         35      168  43.1     2.288   33   \n",
       "..        ...     ...       ...        ...      ...   ...       ...  ...   \n",
       "763        10     101        76         48      180  32.9     0.171   63   \n",
       "764         2     122        70         27        0  36.8     0.340   27   \n",
       "765         5     121        72         23      112  26.2     0.245   30   \n",
       "766         1     126        60          0        0  30.1     0.349   47   \n",
       "767         1      93        70         31        0  30.4     0.315   23   \n",
       "\n",
       "     class  \n",
       "0        1  \n",
       "1        0  \n",
       "2        1  \n",
       "3        0  \n",
       "4        1  \n",
       "..     ...  \n",
       "763      0  \n",
       "764      0  \n",
       "765      0  \n",
       "766      1  \n",
       "767      0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "_db = pymysql.connect(\n",
    "    host=\"ls-a20f4420f7aa9967e25c1e0aecf4d8b641af5f13.cgtgapkuvqbt.ap-northeast-2.rds.amazonaws.com\",\n",
    "    db=\"ML\",\n",
    "    user = \"dbmasteruser\",\n",
    "    password= \"r,3Ipn|O7mL2vL4S)9Q~;7QVdHMV6R9j\",\n",
    "    port = 3306)\n",
    "cursor = _db.cursor(pymysql.cursors.DictCursor)\n",
    "search_sql = 'SELECT * From diabetes'\n",
    "cursor.execute(search_sql)\n",
    "result = cursor.fetchall()\n",
    "diabetes = pd.DataFrame(result)\n",
    "diabetes.columns=[\"pregnant\", \"plasma\", \"pressure\", \"thickness\", \"insulin\", \"BMI\", \"pedigree\", \"age\", \"class\"]\n",
    "diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), slice(0, 9, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3619'>3620</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:142\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), slice(0, 9, None))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\spaceastonomy\\Documents\\GitHub\\GITHUB_TEST\\ml\\2may 2022 deep_learning.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/spaceastonomy/Documents/GitHub/GITHUB_TEST/ml/2may%202022%20deep_learning.ipynb#ch0000008?line=8'>9</a>\u001b[0m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mset_seed(\u001b[39m3\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/spaceastonomy/Documents/GitHub/GITHUB_TEST/ml/2may%202022%20deep_learning.ipynb#ch0000008?line=10'>11</a>\u001b[0m \u001b[39m# Data_set = np.loadtxt(\"./indian_diabetes.csv\",delimiter=\",\")\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/spaceastonomy/Documents/GitHub/GITHUB_TEST/ml/2may%202022%20deep_learning.ipynb#ch0000008?line=12'>13</a>\u001b[0m X \u001b[39m=\u001b[39m diabetes[:,\u001b[39m0\u001b[39;49m:\u001b[39m9\u001b[39;49m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/spaceastonomy/Documents/GitHub/GITHUB_TEST/ml/2may%202022%20deep_learning.ipynb#ch0000008?line=13'>14</a>\u001b[0m Y \u001b[39m=\u001b[39m diabetes[:,\u001b[39m9\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/spaceastonomy/Documents/GitHub/GITHUB_TEST/ml/2may%202022%20deep_learning.ipynb#ch0000008?line=15'>16</a>\u001b[0m model \u001b[39m=\u001b[39m Sequential()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/frame.py?line=3502'>3503</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/frame.py?line=3503'>3504</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/frame.py?line=3504'>3505</a>\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/frame.py?line=3505'>3506</a>\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/frame.py?line=3506'>3507</a>\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3628\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3622'>3623</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3623'>3624</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3624'>3625</a>\u001b[0m         \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3625'>3626</a>\u001b[0m         \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3626'>3627</a>\u001b[0m         \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3627'>3628</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3628'>3629</a>\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/indexes/base.py?line=3630'>3631</a>\u001b[0m \u001b[39m# GH#42269\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5637\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/indexes/base.py?line=5632'>5633</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/indexes/base.py?line=5633'>5634</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/indexes/base.py?line=5634'>5635</a>\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/indexes/base.py?line=5635'>5636</a>\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/indexes/base.py?line=5636'>5637</a>\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), slice(0, 9, None))"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# 딥러닝 구조를 한층씩 쌓을 수 있도록 \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "# Data_set = np.loadtxt(\"./indian_diabetes.csv\",delimiter=\",\")\n",
    "\n",
    "X = diabetes[:,0:8]\n",
    "Y = diabetes[:,8]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X,Y,epochs=100,batch_size=10)\n",
    "\n",
    "print('\\n Accuracy : %.4f' % (model.evaluate(X,Y)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ddbee94c2ce3b61c3b1774ea67d55f2fdae8c29319837f6f09ba2209f9564fc6"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
