{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_price = load_boston()\n",
    "house_price.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = house_price.target\n",
    "print(y_target.shape)\n",
    "plt.hist(y_target, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "\n",
    "def get_scaled_data(method = 'None', p_degree=None, input_data = None):\n",
    "    if method == 'Standard':\n",
    "        scaled_data = StandardScaler().fit_transform(input_data)\n",
    "    elif method == 'MinMax':\n",
    "        scaled_data = MinMaxScaler().fit_transform(input_data)\n",
    "    elif method == 'Log':\n",
    "        scaled_data = np.log1p(input_data)\n",
    "    else :\n",
    "        scaled_data = input_data\n",
    "        \n",
    "    if p_degree != None:\n",
    "        scaled_data = PolynomialFeatures(degree=p_degree,\n",
    "                                         include_bias=False).fit_transform(scaled_data)\n",
    "        \n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "alphas = [0.1, 1, 10, 100]\n",
    "\n",
    "scale_methods=[(None, None), ('Standard', None), ('Standard', 2),\n",
    "               ('MinMax', None), ('MinMax', 2 ), ('Log', None)]\n",
    "\n",
    "for scale_method in scale_methods:\n",
    "    X_data_scaled = get_scaled_data(method=scale_method[0], p_degree=scale_method[1], input_data=house_price.data)\n",
    "    # print('\\n## 변환 유형 : {0}, Polynomial Degree: {1}'.format(scale_method[0], scale_method[1]))\n",
    "    print(f'\\n## 변환 유형 : {scale_method[0]}, Polynomial Degree: {scale_method[1]}' )\n",
    "    \n",
    "    # def get_linear_reg_eval(esimator, params = None, X_data, y_target, verbose=False):\n",
    "    #     get_scaled_data(method= scale_methods[0], p_degree=)\n",
    "    \n",
    "def get_linear_reg_eval(method=\"Ridge\", params=[], X_data_n=None, y_target_n=None, verbose=False) :\n",
    "    result_df = pd.DataFrame()\n",
    "    for param in params :\n",
    "        ridge = Ridge(alpha=param)\n",
    "        neg_mse_scores = cross_val_score(ridge, X_data_n, y_target_n, scoring=\"neg_mean_squared_error\", cv=5, verbose=verbose)\n",
    "        rmse_scores = np.sqrt(-1 * neg_mse_scores)\n",
    "        avg_rmse = np.mean(rmse_scores)\n",
    "        print(f\"alpha {param}일 때 5 folds의 개별 평균 RMSE : {avg_rmse:.4f}\")\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "\n",
    "def get_linear_reg_eval(method=\"Ridge\", params=[], X_data_n=None, y_target_n=None, verbose=True) :\n",
    "    result_df = pd.DataFrame()\n",
    "    for param in params :\n",
    "        ridge = Ridge(alpha=param)\n",
    "        neg_mse_scores = cross_val_score(ridge, X_data_n, y_target_n, scoring=\"neg_mean_squared_error\", cv=5, verbose=verbose)\n",
    "        rmse_scores = np.sqrt(-1 * neg_mse_scores)\n",
    "        avg_rmse = np.mean(rmse_scores)\n",
    "        print(f\"alpha {param}일 때 5 folds의 개별 평균 RMSE : {avg_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge의 alpha값을 다르게 적용하고 다양한 데이터 변환방법에 따른 RMSE 추출.\n",
    "alphas = [0.1, 1, 10, 100]\n",
    "\n",
    "# 변환 방법은 모두 6개, 원본 그대로, 표준정규분포, 표준정규분포+다항식 특성\n",
    "# 최대/최소 정규화, 최대/최소 정규화+다항식 특성, 로그변환\n",
    "scale_methods=[(None, None), (\"Standard\", None), (\"Standard\", 2),\n",
    "                (\"MinMax\", None), (\"MinMax\", 2), (\"Log\", None)]\n",
    "\n",
    "for scale_method in scale_methods :\n",
    "    X_data_scaled = get_scaled_data(method=scale_method[0], p_degree=scale_method[1],\n",
    "                                    input_data=house_price.data)\n",
    "    print(f\"\\n## 변환 유형:{scale_method[0]}, Polynomial Degree:{scale_method[1]}\")\n",
    "\n",
    "    # alpha 값에 따른 회귀 모델의 폴드 평균 RMSE를 출력하고,\n",
    "    # 회귀 계수값들을 DataFrame으로 반환해주는 함수\n",
    "    get_linear_reg_eval(\"Ridge\", params=alphas, X_data_n=X_data_scaled,\n",
    "                        y_target_n=y_target, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(cancer.data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data_scaled, cancer.target, test_size=0.3, random_state=0\n",
    ")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_preds = lr_clf.predict(X_test)\n",
    "\n",
    "print(f'accuracy : {accuracy_score(y_test, lr_preds)}')\n",
    "print(f'roc_auc : {roc_auc_score(y_test, lr_preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor \n",
    "\n",
    "boston = load_boston()\n",
    "bostonDF = pd.DataFrame(boston.data, columns= boston.feature_names)\n",
    "\n",
    "\n",
    "bostonDF['PRICE'] = boston.target\n",
    "X_target = bostonDF['PRICE']\n",
    "X_data = bostonDF.drop(['PRICE'], axis=1, inplace= False)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=0, n_estimators=1000)\n",
    "neg_mse_scores = cross_val_score(rf, X_data, y_target, scoring='neg_mean_squared_error', cv=5)\n",
    "rmse_scores = np.sqrt(-1 * neg_mse_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "\n",
    "\n",
    "dt_reg = DecisionTreeRegressor(random_state=0, max_depth=4)\n",
    "rf_reg = RandomForestRegressor(random_state=0, n_estimators=1000)\n",
    "xg_reg = XGBRegressor(random_state = 0, n_estimators=1000)\n",
    "\n",
    "models = [dt_reg, rf_reg, xg_reg]\n",
    "for model in models:\n",
    "    get_model_cv_prediction(model=None, X_data=None, y_target=None)\n",
    "    \n",
    "\n",
    "print(f'5교차 검증의 개별 Negative MSE score : {np.round(neg_mse_scores, 2)}')\n",
    "print(f'5교차 검증의 개별 RMSE scores : {np.round(rmse_scores, 2) }')\n",
    "print(f'5교차 검증의 평균 RMSE : {avg_rmse : .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_reg = DecisionTreeRegressor(random_state=0, max_depth=4)\n",
    "rf_reg = RandomForestRegressor(random_state=0, n_estimators=1000)\n",
    "xg_reg = XGBRegressor(random_state = 0, n_estimators=1000)\n",
    "\n",
    "models = [dt_reg, rf_reg, xg_reg]\n",
    "for model in models:\n",
    "    get_model_cv_prediction(model, X_data, y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_cv_prediction(model=None, X_data=None, y_target=None) :\n",
    "    neg_mse_scores = cross_val_score(model, X_data, y_target, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "    rmse_scores = np.sqrt(-1*neg_mse_scores)\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    if model == dt_reg :\n",
    "        print(f\"### DecisionTreeRegressor ### \\n5 교차 검증의 평균 RMSE : {np.round(avg_rmse,3)}\")\n",
    "    elif model == rf_reg :\n",
    "        print(f\"### RandomForestRegressor ### \\n5 교차 검증의 평균 RMSE : {np.round(avg_rmse,3)}\")\n",
    "    else :\n",
    "        print(f\"### XGBRegressor ### \\n5 교차 검증의 평균 RMSE : {np.round(avg_rmse,3)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ddbee94c2ce3b61c3b1774ea67d55f2fdae8c29319837f6f09ba2209f9564fc6"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
