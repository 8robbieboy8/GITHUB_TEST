{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn.ensemble.GradientBoostingClassifier\n",
    "* class sklearn.ensemble.GradientBoostingClassifier(*, loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def get_human_dataset() :\n",
    "\n",
    "    # 각 데이터 파일들은 공백으로 분리되어 있으므로 read_csv에서 공백 문자를 sep으로 할당\n",
    "    featuer_name_df = pd.read_csv(\"./UCI HAR Dataset/features.txt\", sep=\"\\s+\",\n",
    "                              header=None, names=[\"column_index\", \"column_name\"])\n",
    "\n",
    "\n",
    "    # 중복된 피처명을 수정하는 get_new_feature_name_df() 를 이용, 신규 피처명 DF 생성\n",
    "    new_feature_name_df = get_new_feature_name_df(featuer_name_df)\n",
    "\n",
    "    # DataFrame에 피처명을 칼럼으로 부여하기 위해 리스트 객체로 다시 변환\n",
    "    featuer_name = new_feature_name_df.iloc[:, 1].values.tolist()\n",
    "\n",
    "    # 학습 피처 데이터 셋과 테스스 피처 데이터를 DF로 로딩, 컬럼명은 feature_name 적용\n",
    "    X_train = pd.read_csv(\"./UCI HAR Dataset/train/X_train.txt\",\n",
    "                          sep=\"\\s+\", names=featuer_name)\n",
    "    X_test = pd.read_csv(\"./UCI HAR Dataset/test/X_test.txt\",\n",
    "                          sep=\"\\s+\", names=featuer_name)\n",
    "\n",
    "    # 학습 레이블과 테스트 레이블 데이터를 DF로 로딩하고 컬럼명은 action으로 부여\n",
    "    # \"\\s+\" 데이터 사이 간격 공백으로 구분\n",
    "    y_train = pd.read_csv(\"./UCI HAR Dataset/train/y_train.txt\",\n",
    "                          sep=\"\\s+\", header=None, names=[\"action\"])\n",
    "    y_test = pd.read_csv(\"./UCI HAR Dataset/test/y_test.txt\",\n",
    "                          sep=\"\\s+\", header=None, names=[\"action\"])\n",
    "\n",
    "    # 로드된 학습/테스트용 DF를 모두 반환\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def get_new_feature_name_df(old_feature_name_df) :\n",
    "    feature_dup_df = pd.DataFrame(data=old_feature_name_df.groupby(\"column_name\").cumcount(),\n",
    "                                  columns=[\"dup_cnt\"])\n",
    "    feature_dup_df = feature_dup_df.reset_index()\n",
    "    new_feature_name_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how=\"outer\")\n",
    "    new_feature_name_df[\"column_name\"] = new_feature_name_df[[\"column_name\", \"dup_cnt\"]].apply(lambda x : x[0]+\"_\"+str(x[1])\n",
    "                                                                                        if x[1]>0 else x[0], axis=1)\n",
    "    new_feature_name_df = new_feature_name_df.drop([\"index\"], axis=1)\n",
    "    return new_feature_name_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     column_index                           column_name\n",
      "0               1                     tBodyAcc-mean()-X\n",
      "1               2                     tBodyAcc-mean()-Y\n",
      "2               3                     tBodyAcc-mean()-Z\n",
      "3               4                      tBodyAcc-std()-X\n",
      "4               5                      tBodyAcc-std()-Y\n",
      "..            ...                                   ...\n",
      "556           557      angle(tBodyGyroMean,gravityMean)\n",
      "557           558  angle(tBodyGyroJerkMean,gravityMean)\n",
      "558           559                  angle(X,gravityMean)\n",
      "559           560                  angle(Y,gravityMean)\n",
      "560           561                  angle(Z,gravityMean)\n",
      "\n",
      "[561 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "featuer_name_df = pd.read_csv(\"./UCI HAR Dataset/features.txt\", sep=\"\\s+\",\n",
    "                              header=None, names=[\"column_index\", \"column_name\"])\n",
    "print(featuer_name_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\apps\\ml\\14April 2022 data.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/apps/ml/14April%202022%20data.ipynb#ch0000003?line=7'>8</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/14April%202022%20data.ipynb#ch0000003?line=9'>10</a>\u001b[0m gb_clf \u001b[39m=\u001b[39m GradientBoostingClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/apps/ml/14April%202022%20data.ipynb#ch0000003?line=10'>11</a>\u001b[0m gb_clf\u001b[39m.\u001b[39;49mfit(X_trian, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/14April%202022%20data.ipynb#ch0000003?line=11'>12</a>\u001b[0m gb_pred \u001b[39m=\u001b[39m gb_clf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/14April%202022%20data.ipynb#ch0000003?line=12'>13</a>\u001b[0m gb_accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, gb_pred)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:586\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=582'>583</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resize_state()\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=584'>585</a>\u001b[0m \u001b[39m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=585'>586</a>\u001b[0m n_stages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stages(\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=586'>587</a>\u001b[0m     X,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=587'>588</a>\u001b[0m     y,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=588'>589</a>\u001b[0m     raw_predictions,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=589'>590</a>\u001b[0m     sample_weight,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=590'>591</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rng,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=591'>592</a>\u001b[0m     X_val,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=592'>593</a>\u001b[0m     y_val,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=593'>594</a>\u001b[0m     sample_weight_val,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=594'>595</a>\u001b[0m     begin_at_stage,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=595'>596</a>\u001b[0m     monitor,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=596'>597</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=598'>599</a>\u001b[0m \u001b[39m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=599'>600</a>\u001b[0m \u001b[39mif\u001b[39;00m n_stages \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:663\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=655'>656</a>\u001b[0m     old_oob_score \u001b[39m=\u001b[39m loss_(\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=656'>657</a>\u001b[0m         y[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=657'>658</a>\u001b[0m         raw_predictions[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=658'>659</a>\u001b[0m         sample_weight[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=659'>660</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=661'>662</a>\u001b[0m \u001b[39m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=662'>663</a>\u001b[0m raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stage(\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=663'>664</a>\u001b[0m     i,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=664'>665</a>\u001b[0m     X,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=665'>666</a>\u001b[0m     y,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=666'>667</a>\u001b[0m     raw_predictions,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=667'>668</a>\u001b[0m     sample_weight,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=668'>669</a>\u001b[0m     sample_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=669'>670</a>\u001b[0m     random_state,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=670'>671</a>\u001b[0m     X_csc,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=671'>672</a>\u001b[0m     X_csr,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=672'>673</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=674'>675</a>\u001b[0m \u001b[39m# track deviance (= loss)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=675'>676</a>\u001b[0m \u001b[39mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:246\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=242'>243</a>\u001b[0m     sample_weight \u001b[39m=\u001b[39m sample_weight \u001b[39m*\u001b[39m sample_mask\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=244'>245</a>\u001b[0m X \u001b[39m=\u001b[39m X_csr \u001b[39mif\u001b[39;00m X_csr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m X\n\u001b[1;32m--> <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=245'>246</a>\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X, residual, sample_weight\u001b[39m=\u001b[39;49msample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=247'>248</a>\u001b[0m \u001b[39m# update tree leaves\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=248'>249</a>\u001b[0m loss\u001b[39m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=249'>250</a>\u001b[0m     tree\u001b[39m.\u001b[39mtree_,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=250'>251</a>\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=257'>258</a>\u001b[0m     k\u001b[39m=\u001b[39mk,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=258'>259</a>\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:1315\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=1277'>1278</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=1278'>1279</a>\u001b[0m     \u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, X_idx_sorted\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=1279'>1280</a>\u001b[0m ):\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=1280'>1281</a>\u001b[0m     \u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=1281'>1282</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=1282'>1283</a>\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=1311'>1312</a>\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=1312'>1313</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=1314'>1315</a>\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=1315'>1316</a>\u001b[0m         X,\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=1316'>1317</a>\u001b[0m         y,\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=1317'>1318</a>\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=1318'>1319</a>\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=1319'>1320</a>\u001b[0m         X_idx_sorted\u001b[39m=\u001b[39;49mX_idx_sorted,\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=1320'>1321</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=1321'>1322</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=408'>409</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=409'>410</a>\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=410'>411</a>\u001b[0m         splitter,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=411'>412</a>\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=416'>417</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=417'>418</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=419'>420</a>\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=421'>422</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/tree/_classes.py?line=422'>423</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "\n",
    "print('GBM 정확도 {0:.4f}'.format(gb_accuracy))\n",
    "print(f'GBM 정확도 {gb_accuracy:.4f}')\n",
    "print('GBM 수행시간: {0:.1f} 초'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class xgboost.XGBRegressor(*, objective='reg:squarederror', **kwargs)\n",
    "Parameters\n",
    "\n",
    "-   **n_estimators**  ([_int_](https://docs.python.org/3.6/library/functions.html#int \"(in Python v3.6)\")) – Number of gradient boosted trees. Equivalent to number of boosting rounds.\n",
    "    \n",
    "-   **max_depth**  (_Optional__[_[_int_](https://docs.python.org/3.6/library/functions.html#int \"(in Python v3.6)\")_]_) – Maximum tree depth for base learners.\n",
    "    \n",
    "-   **learning_rate**  (_Optional__[_[_float_](https://docs.python.org/3.6/library/functions.html#float \"(in Python v3.6)\")_]_) – Boosting learning rate (xgb's \"eta\")\n",
    "    \n",
    "-   **verbosity**  (_Optional__[_[_int_](https://docs.python.org/3.6/library/functions.html#int \"(in Python v3.6)\")_]_) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
    "    \n",
    "-   **objective**  ([_Union_](https://docs.python.org/3.6/library/typing.html#typing.Union \"(in Python v3.6)\")_[_[_str_](https://docs.python.org/3.6/library/stdtypes.html#str \"(in Python v3.6)\")_,_ [_Callable_](https://docs.python.org/3.6/library/typing.html#typing.Callable \"(in Python v3.6)\")_[__[_[_numpy.ndarray_](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray \"(in NumPy v1.22)\")_,_ [_numpy.ndarray_](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray \"(in NumPy v1.22)\")_]__,_ [_Tuple_](https://docs.python.org/3.6/library/typing.html#typing.Tuple \"(in Python v3.6)\")_[_[_numpy.ndarray_](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray \"(in NumPy v1.22)\")_,_ [_numpy.ndarray_](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray \"(in NumPy v1.22)\")_]__]__,_ _NoneType__]_) – Specify the learning task and the corresponding learning objective or a custom objective function to be used (see note below).\n",
    "    \n",
    "-   **booster**  (_Optional__[_[_str_](https://docs.python.org/3.6/library/stdtypes.html#str \"(in Python v3.6)\")_]_) – Specify which booster to use: gbtree, gblinear or dart.\n",
    "    \n",
    "-   **tree_method**  (_Optional__[_[_str_](https://docs.python.org/3.6/library/stdtypes.html#str \"(in Python v3.6)\")_]_) – Specify which tree method to use. Default to auto. If this parameter is set to default, XGBoost will choose the most conservative option available. It's recommended to study this option from the parameters document:  [https://xgboost.readthedocs.io/en/latest/treemethod.html](https://xgboost.readthedocs.io/en/latest/treemethod.html).\n",
    "    \n",
    "-   **n_jobs**  (_Optional__[_[_int_](https://docs.python.org/3.6/library/functions.html#int \"(in Python v3.6)\")_]_) – Number of parallel threads used to run xgboost. When used with other Scikit-Learn algorithms like grid search, you may choose which algorithm to parallelize and balance the threads. Creating thread contention will significantly slow down both algorithms.\n",
    "    \n",
    "-   **gamma**  (_Optional__[_[_float_](https://docs.python.org/3.6/library/functions.html#float \"(in Python v3.6)\")_]_) – Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
    "    \n",
    "-   **min_child_weight**  (_Optional__[_[_float_](https://docs.python.org/3.6/library/functions.html#float \"(in Python v3.6)\")_]_) – Minimum sum of instance weight(hessian) needed in a child.\n",
    "    \n",
    "-   **max_delta_step**  (_Optional__[_[_float_](https://docs.python.org/3.6/library/functions.html#float \"(in Python v3.6)\")_]_) – Maximum delta step we allow each tree's weight estimation to be.\n",
    "    \n",
    "-   **subsample**  (_Optional__[_[_float_](https://docs.python.org/3.6/library/functions.html#float \"(in Python v3.6)\")_]_) – Subsample ratio of the training instance.\n",
    "    \n",
    "-   **colsample_bytree**  (_Optional__[_[_float_](https://docs.python.org/3.6/library/functions.html#float \"(in Python v3.6)\")_]_) – Subsample ratio of columns when constructing each tree.\n",
    "    \n",
    "-   **colsample_bylevel**  (_Optional__[_[_float_](https://docs.python.org/3.6/library/functions.html#float \"(in Python v3.6)\")_]_) – Subsample ratio of columns for each level.\n",
    "    \n",
    "-   **colsample_bynode**  (_Optional__[_[_float_](https://docs.python.org/3.6/library/functions.html#float \"(in Python v3.6)\")_]_) – Subsample ratio of columns for each split.\n",
    "    \n",
    "-   **reg_alpha**  (_Optional__[_[_float_](https://docs.python.org/3.6/library/functions.html#float \"(in Python v3.6)\")_]_) – L1 regularization term on weights (xgb's alpha).\n",
    "    \n",
    "-   **reg_lambda**  (_Optional__[_[_float_](https://docs.python.org/3.6/library/functions.html#float \"(in Python v3.6)\")_]_) – L2 regularization term on weights (xgb's lambda).\n",
    "    \n",
    "-   **scale_pos_weight**  (_Optional__[_[_float_](https://docs.python.org/3.6/library/functions.html#float \"(in Python v3.6)\")_]_) – Balancing of positive and negative weights.\n",
    "    \n",
    "-   **base_score**  (_Optional__[_[_float_](https://docs.python.org/3.6/library/functions.html#float \"(in Python v3.6)\")_]_) – The initial prediction score of all instances, global bias.\n",
    "    \n",
    "-   **random_state**  (_Optional__[__Union__[_[_numpy.random.RandomState_](https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState \"(in NumPy v1.22)\")_,_ [_int_](https://docs.python.org/3.6/library/functions.html#int \"(in Python v3.6)\")_]__]_) –"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\apps\\ml\\14April 2022 data.ipynb Cell 7'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/apps/ml/14April%202022%20data.ipynb#ch0000006?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mxgboost\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mxgb\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/apps/ml/14April%202022%20data.ipynb#ch0000006?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mxgboost\u001b[39;00m \u001b[39mimport\u001b[39;00m plot_importace\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/apps/ml/14April%202022%20data.ipynb#ch0000006?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importace\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from xgboost import XGB \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "X_features = dataset.data\n",
    "y_labels = dataset.target\n",
    "\n",
    "cancer_df = pd.DataFrame(data = X_features, columns = dataset.feature_names)\n",
    "cancer_df['target'] = y_labels\n",
    "\n",
    "cancer_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dict = {\"키움증권\" : 5000, \"카카오\" : 3000, \"네이버\" : 2000}\n",
    "ee_bool = True\n",
    "while ee_bool:\n",
    "    a_dict['키움증권'] = a_dict['키움증권'] + 1000\n",
    "\n",
    "    if a_dict['키움증권'] == 10000:\n",
    "        a_dict.update({\"이베스트증권\" : 5000})\n",
    "        break\n",
    "\n",
    "print(a_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저는 coffee를 좋아합니다. 하루 5잔 마셔요\n"
     ]
    }
   ],
   "source": [
    "s = 'coffee'\n",
    "n = 5\n",
    "\n",
    "print(f'저는 {s}를 좋아합니다. 하루 {n}잔 마셔요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소수점 두자리:         3.14\n"
     ]
    }
   ],
   "source": [
    "pi = 3.1416\n",
    "\n",
    "print(f'소수점 두자리: {pi: 12.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "[5.1 3.5 1.4 0.2]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "print(iris.feature_names)\n",
    "print(iris.target_names)\n",
    "print(iris.data[0])\n",
    "print(iris.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0: lable 0, features [5.1 3.5 1.4 0.2]\n",
      "Example 1: lable 0, features [4.9 3.  1.4 0.2]\n",
      "Example 2: lable 0, features [4.7 3.2 1.3 0.2]\n",
      "Example 3: lable 0, features [4.6 3.1 1.5 0.2]\n",
      "Example 4: lable 0, features [5.  3.6 1.4 0.2]\n",
      "Example 5: lable 0, features [5.4 3.9 1.7 0.4]\n",
      "Example 6: lable 0, features [4.6 3.4 1.4 0.3]\n",
      "Example 7: lable 0, features [5.  3.4 1.5 0.2]\n",
      "Example 8: lable 0, features [4.4 2.9 1.4 0.2]\n",
      "Example 9: lable 0, features [4.9 3.1 1.5 0.1]\n",
      "Example 10: lable 0, features [5.4 3.7 1.5 0.2]\n",
      "Example 11: lable 0, features [4.8 3.4 1.6 0.2]\n",
      "Example 12: lable 0, features [4.8 3.  1.4 0.1]\n",
      "Example 13: lable 0, features [4.3 3.  1.1 0.1]\n",
      "Example 14: lable 0, features [5.8 4.  1.2 0.2]\n",
      "Example 15: lable 0, features [5.7 4.4 1.5 0.4]\n",
      "Example 16: lable 0, features [5.4 3.9 1.3 0.4]\n",
      "Example 17: lable 0, features [5.1 3.5 1.4 0.3]\n",
      "Example 18: lable 0, features [5.7 3.8 1.7 0.3]\n",
      "Example 19: lable 0, features [5.1 3.8 1.5 0.3]\n",
      "Example 20: lable 0, features [5.4 3.4 1.7 0.2]\n",
      "Example 21: lable 0, features [5.1 3.7 1.5 0.4]\n",
      "Example 22: lable 0, features [4.6 3.6 1.  0.2]\n",
      "Example 23: lable 0, features [5.1 3.3 1.7 0.5]\n",
      "Example 24: lable 0, features [4.8 3.4 1.9 0.2]\n",
      "Example 25: lable 0, features [5.  3.  1.6 0.2]\n",
      "Example 26: lable 0, features [5.  3.4 1.6 0.4]\n",
      "Example 27: lable 0, features [5.2 3.5 1.5 0.2]\n",
      "Example 28: lable 0, features [5.2 3.4 1.4 0.2]\n",
      "Example 29: lable 0, features [4.7 3.2 1.6 0.2]\n",
      "Example 30: lable 0, features [4.8 3.1 1.6 0.2]\n",
      "Example 31: lable 0, features [5.4 3.4 1.5 0.4]\n",
      "Example 32: lable 0, features [5.2 4.1 1.5 0.1]\n",
      "Example 33: lable 0, features [5.5 4.2 1.4 0.2]\n",
      "Example 34: lable 0, features [4.9 3.1 1.5 0.2]\n",
      "Example 35: lable 0, features [5.  3.2 1.2 0.2]\n",
      "Example 36: lable 0, features [5.5 3.5 1.3 0.2]\n",
      "Example 37: lable 0, features [4.9 3.6 1.4 0.1]\n",
      "Example 38: lable 0, features [4.4 3.  1.3 0.2]\n",
      "Example 39: lable 0, features [5.1 3.4 1.5 0.2]\n",
      "Example 40: lable 0, features [5.  3.5 1.3 0.3]\n",
      "Example 41: lable 0, features [4.5 2.3 1.3 0.3]\n",
      "Example 42: lable 0, features [4.4 3.2 1.3 0.2]\n",
      "Example 43: lable 0, features [5.  3.5 1.6 0.6]\n",
      "Example 44: lable 0, features [5.1 3.8 1.9 0.4]\n",
      "Example 45: lable 0, features [4.8 3.  1.4 0.3]\n",
      "Example 46: lable 0, features [5.1 3.8 1.6 0.2]\n",
      "Example 47: lable 0, features [4.6 3.2 1.4 0.2]\n",
      "Example 48: lable 0, features [5.3 3.7 1.5 0.2]\n",
      "Example 49: lable 0, features [5.  3.3 1.4 0.2]\n",
      "Example 50: lable 1, features [7.  3.2 4.7 1.4]\n",
      "Example 51: lable 1, features [6.4 3.2 4.5 1.5]\n",
      "Example 52: lable 1, features [6.9 3.1 4.9 1.5]\n",
      "Example 53: lable 1, features [5.5 2.3 4.  1.3]\n",
      "Example 54: lable 1, features [6.5 2.8 4.6 1.5]\n",
      "Example 55: lable 1, features [5.7 2.8 4.5 1.3]\n",
      "Example 56: lable 1, features [6.3 3.3 4.7 1.6]\n",
      "Example 57: lable 1, features [4.9 2.4 3.3 1. ]\n",
      "Example 58: lable 1, features [6.6 2.9 4.6 1.3]\n",
      "Example 59: lable 1, features [5.2 2.7 3.9 1.4]\n",
      "Example 60: lable 1, features [5.  2.  3.5 1. ]\n",
      "Example 61: lable 1, features [5.9 3.  4.2 1.5]\n",
      "Example 62: lable 1, features [6.  2.2 4.  1. ]\n",
      "Example 63: lable 1, features [6.1 2.9 4.7 1.4]\n",
      "Example 64: lable 1, features [5.6 2.9 3.6 1.3]\n",
      "Example 65: lable 1, features [6.7 3.1 4.4 1.4]\n",
      "Example 66: lable 1, features [5.6 3.  4.5 1.5]\n",
      "Example 67: lable 1, features [5.8 2.7 4.1 1. ]\n",
      "Example 68: lable 1, features [6.2 2.2 4.5 1.5]\n",
      "Example 69: lable 1, features [5.6 2.5 3.9 1.1]\n",
      "Example 70: lable 1, features [5.9 3.2 4.8 1.8]\n",
      "Example 71: lable 1, features [6.1 2.8 4.  1.3]\n",
      "Example 72: lable 1, features [6.3 2.5 4.9 1.5]\n",
      "Example 73: lable 1, features [6.1 2.8 4.7 1.2]\n",
      "Example 74: lable 1, features [6.4 2.9 4.3 1.3]\n",
      "Example 75: lable 1, features [6.6 3.  4.4 1.4]\n",
      "Example 76: lable 1, features [6.8 2.8 4.8 1.4]\n",
      "Example 77: lable 1, features [6.7 3.  5.  1.7]\n",
      "Example 78: lable 1, features [6.  2.9 4.5 1.5]\n",
      "Example 79: lable 1, features [5.7 2.6 3.5 1. ]\n",
      "Example 80: lable 1, features [5.5 2.4 3.8 1.1]\n",
      "Example 81: lable 1, features [5.5 2.4 3.7 1. ]\n",
      "Example 82: lable 1, features [5.8 2.7 3.9 1.2]\n",
      "Example 83: lable 1, features [6.  2.7 5.1 1.6]\n",
      "Example 84: lable 1, features [5.4 3.  4.5 1.5]\n",
      "Example 85: lable 1, features [6.  3.4 4.5 1.6]\n",
      "Example 86: lable 1, features [6.7 3.1 4.7 1.5]\n",
      "Example 87: lable 1, features [6.3 2.3 4.4 1.3]\n",
      "Example 88: lable 1, features [5.6 3.  4.1 1.3]\n",
      "Example 89: lable 1, features [5.5 2.5 4.  1.3]\n",
      "Example 90: lable 1, features [5.5 2.6 4.4 1.2]\n",
      "Example 91: lable 1, features [6.1 3.  4.6 1.4]\n",
      "Example 92: lable 1, features [5.8 2.6 4.  1.2]\n",
      "Example 93: lable 1, features [5.  2.3 3.3 1. ]\n",
      "Example 94: lable 1, features [5.6 2.7 4.2 1.3]\n",
      "Example 95: lable 1, features [5.7 3.  4.2 1.2]\n",
      "Example 96: lable 1, features [5.7 2.9 4.2 1.3]\n",
      "Example 97: lable 1, features [6.2 2.9 4.3 1.3]\n",
      "Example 98: lable 1, features [5.1 2.5 3.  1.1]\n",
      "Example 99: lable 1, features [5.7 2.8 4.1 1.3]\n",
      "Example 100: lable 2, features [6.3 3.3 6.  2.5]\n",
      "Example 101: lable 2, features [5.8 2.7 5.1 1.9]\n",
      "Example 102: lable 2, features [7.1 3.  5.9 2.1]\n",
      "Example 103: lable 2, features [6.3 2.9 5.6 1.8]\n",
      "Example 104: lable 2, features [6.5 3.  5.8 2.2]\n",
      "Example 105: lable 2, features [7.6 3.  6.6 2.1]\n",
      "Example 106: lable 2, features [4.9 2.5 4.5 1.7]\n",
      "Example 107: lable 2, features [7.3 2.9 6.3 1.8]\n",
      "Example 108: lable 2, features [6.7 2.5 5.8 1.8]\n",
      "Example 109: lable 2, features [7.2 3.6 6.1 2.5]\n",
      "Example 110: lable 2, features [6.5 3.2 5.1 2. ]\n",
      "Example 111: lable 2, features [6.4 2.7 5.3 1.9]\n",
      "Example 112: lable 2, features [6.8 3.  5.5 2.1]\n",
      "Example 113: lable 2, features [5.7 2.5 5.  2. ]\n",
      "Example 114: lable 2, features [5.8 2.8 5.1 2.4]\n",
      "Example 115: lable 2, features [6.4 3.2 5.3 2.3]\n",
      "Example 116: lable 2, features [6.5 3.  5.5 1.8]\n",
      "Example 117: lable 2, features [7.7 3.8 6.7 2.2]\n",
      "Example 118: lable 2, features [7.7 2.6 6.9 2.3]\n",
      "Example 119: lable 2, features [6.  2.2 5.  1.5]\n",
      "Example 120: lable 2, features [6.9 3.2 5.7 2.3]\n",
      "Example 121: lable 2, features [5.6 2.8 4.9 2. ]\n",
      "Example 122: lable 2, features [7.7 2.8 6.7 2. ]\n",
      "Example 123: lable 2, features [6.3 2.7 4.9 1.8]\n",
      "Example 124: lable 2, features [6.7 3.3 5.7 2.1]\n",
      "Example 125: lable 2, features [7.2 3.2 6.  1.8]\n",
      "Example 126: lable 2, features [6.2 2.8 4.8 1.8]\n",
      "Example 127: lable 2, features [6.1 3.  4.9 1.8]\n",
      "Example 128: lable 2, features [6.4 2.8 5.6 2.1]\n",
      "Example 129: lable 2, features [7.2 3.  5.8 1.6]\n",
      "Example 130: lable 2, features [7.4 2.8 6.1 1.9]\n",
      "Example 131: lable 2, features [7.9 3.8 6.4 2. ]\n",
      "Example 132: lable 2, features [6.4 2.8 5.6 2.2]\n",
      "Example 133: lable 2, features [6.3 2.8 5.1 1.5]\n",
      "Example 134: lable 2, features [6.1 2.6 5.6 1.4]\n",
      "Example 135: lable 2, features [7.7 3.  6.1 2.3]\n",
      "Example 136: lable 2, features [6.3 3.4 5.6 2.4]\n",
      "Example 137: lable 2, features [6.4 3.1 5.5 1.8]\n",
      "Example 138: lable 2, features [6.  3.  4.8 1.8]\n",
      "Example 139: lable 2, features [6.9 3.1 5.4 2.1]\n",
      "Example 140: lable 2, features [6.7 3.1 5.6 2.4]\n",
      "Example 141: lable 2, features [6.9 3.1 5.1 2.3]\n",
      "Example 142: lable 2, features [5.8 2.7 5.1 1.9]\n",
      "Example 143: lable 2, features [6.8 3.2 5.9 2.3]\n",
      "Example 144: lable 2, features [6.7 3.3 5.7 2.5]\n",
      "Example 145: lable 2, features [6.7 3.  5.2 2.3]\n",
      "Example 146: lable 2, features [6.3 2.5 5.  1.9]\n",
      "Example 147: lable 2, features [6.5 3.  5.2 2. ]\n",
      "Example 148: lable 2, features [6.2 3.4 5.4 2.3]\n",
      "Example 149: lable 2, features [5.9 3.  5.1 1.8]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "for i in range(len(iris.target)):\n",
    "    print('Example %d: lable %s, features %s' %(i, iris.target[i], iris.data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x259bb4bcac0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = load_iris()\n",
    "sepal = iris.data[:, 0:2]\n",
    "kind = iris.target\n",
    "plt.xlabel('Sepal Length')\n",
    "plt.ylabel('Sepal Width')\n",
    "plt.plot(sepal[kind == 0][:, 0], sepal[kind == 0][:, 1], \n",
    "                        \"ro\", label = 'Setosa')\n",
    "plt.plot(sepal[kind == 0][:, 0], sepal[kind == 0][:, 1], \n",
    "                        \"bo\", label = 'Versicolor')\n",
    "plt.plot(sepal[kind == 0][:, 0], sepal[kind == 0][:, 1], \n",
    "                        \"yo\", label = 'Virginica')\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n",
      "(30, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 6)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "scores = metrics.accuracy_score(y_test, y_pred)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versicolor\n",
      "setosa\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X, y)\n",
    "\n",
    "classes = {0:'setosa', 1:'versicolor', 2:'virginica'}\n",
    "\n",
    "x_new = [[3,4,5,2], [5,4,2,2]]\n",
    "y_predict = knn.predict(x_new)\n",
    "\n",
    "print(classes[y_predict[0]])\n",
    "print(classes[y_predict[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression,make_classification\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X, y = make_classification(n_samples=100,n_features=10,n_informative=2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "# it takes a list of tuples as parameter\n",
    "pipeline = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', LogisticRegression())\n",
    "\t])\n",
    "\n",
    "# use the pipeline object as you would\n",
    "# a regular classifier\n",
    "pipeline.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_preds = pipeline.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\apps\\ml\\14April 2022 data.ipynb Cell 20'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/apps/ml/14April%202022%20data.ipynb#ch0000027?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m fetch_20newsgroups\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/apps/ml/14April%202022%20data.ipynb#ch0000027?line=7'>8</a>\u001b[0m cats \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39malt.atheism\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msci.space\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/apps/ml/14April%202022%20data.ipynb#ch0000027?line=8'>9</a>\u001b[0m newsgroups_train \u001b[39m=\u001b[39m fetch_20newsgroups(subset\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, categories\u001b[39m=\u001b[39;49mcats)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/14April%202022%20data.ipynb#ch0000027?line=9'>10</a>\u001b[0m newsgroups_test \u001b[39m=\u001b[39m fetch_20newsgroups(subset\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m, categories\u001b[39m=\u001b[39mcats)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/14April%202022%20data.ipynb#ch0000027?line=11'>12</a>\u001b[0m X_train \u001b[39m=\u001b[39m newsgroups_train\u001b[39m.\u001b[39mdata\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\datasets\\_twenty_newsgroups.py:264\u001b[0m, in \u001b[0;36mfetch_20newsgroups\u001b[1;34m(data_home, subset, categories, shuffle, random_state, remove, download_if_missing, return_X_y)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/datasets/_twenty_newsgroups.py?line=261'>262</a>\u001b[0m \u001b[39mif\u001b[39;00m download_if_missing:\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/datasets/_twenty_newsgroups.py?line=262'>263</a>\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mDownloading 20news dataset. This may take a few minutes.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/datasets/_twenty_newsgroups.py?line=263'>264</a>\u001b[0m     cache \u001b[39m=\u001b[39m _download_20newsgroups(\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/datasets/_twenty_newsgroups.py?line=264'>265</a>\u001b[0m         target_dir\u001b[39m=\u001b[39;49mtwenty_home, cache_path\u001b[39m=\u001b[39;49mcache_path\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/datasets/_twenty_newsgroups.py?line=265'>266</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/datasets/_twenty_newsgroups.py?line=266'>267</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/datasets/_twenty_newsgroups.py?line=267'>268</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m20Newsgroups dataset not found\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\datasets\\_twenty_newsgroups.py:74\u001b[0m, in \u001b[0;36m_download_20newsgroups\u001b[1;34m(target_dir, cache_path)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/datasets/_twenty_newsgroups.py?line=70'>71</a>\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(target_dir)\n\u001b[0;32m     <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/datasets/_twenty_newsgroups.py?line=72'>73</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mDownloading dataset from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (14 MB)\u001b[39m\u001b[39m\"\u001b[39m, ARCHIVE\u001b[39m.\u001b[39murl)\n\u001b[1;32m---> <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/datasets/_twenty_newsgroups.py?line=73'>74</a>\u001b[0m archive_path \u001b[39m=\u001b[39m _fetch_remote(ARCHIVE, dirname\u001b[39m=\u001b[39;49mtarget_dir)\n\u001b[0;32m     <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/datasets/_twenty_newsgroups.py?line=75'>76</a>\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mDecompressing \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, archive_path)\n\u001b[0;32m     <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/datasets/_twenty_newsgroups.py?line=76'>77</a>\u001b[0m tarfile\u001b[39m.\u001b[39mopen(archive_path, \u001b[39m\"\u001b[39m\u001b[39mr:gz\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mextractall(path\u001b[39m=\u001b[39mtarget_dir)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\datasets\\_base.py:1454\u001b[0m, in \u001b[0;36m_fetch_remote\u001b[1;34m(remote, dirname)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/datasets/_base.py?line=1431'>1432</a>\u001b[0m \u001b[39m\"\"\"Helper function to download a remote dataset into path\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/datasets/_base.py?line=1432'>1433</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/datasets/_base.py?line=1433'>1434</a>\u001b[0m \u001b[39mFetch a dataset pointed by remote's url, save into path using remote's\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/datasets/_base.py?line=1449'>1450</a>\u001b[0m \u001b[39m    Full path of the created file.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/datasets/_base.py?line=1450'>1451</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/datasets/_base.py?line=1452'>1453</a>\u001b[0m file_path \u001b[39m=\u001b[39m remote\u001b[39m.\u001b[39mfilename \u001b[39mif\u001b[39;00m dirname \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m join(dirname, remote\u001b[39m.\u001b[39mfilename)\n\u001b[1;32m-> <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/datasets/_base.py?line=1453'>1454</a>\u001b[0m urlretrieve(remote\u001b[39m.\u001b[39;49murl, file_path)\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/datasets/_base.py?line=1454'>1455</a>\u001b[0m checksum \u001b[39m=\u001b[39m _sha256(file_path)\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/datasets/_base.py?line=1455'>1456</a>\u001b[0m \u001b[39mif\u001b[39;00m remote\u001b[39m.\u001b[39mchecksum \u001b[39m!=\u001b[39m checksum:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:270\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/urllib/request.py?line=266'>267</a>\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/urllib/request.py?line=268'>269</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/urllib/request.py?line=269'>270</a>\u001b[0m     block \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39;49mread(bs)\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/urllib/request.py?line=270'>271</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m block:\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/urllib/request.py?line=271'>272</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/http/client.py?line=461'>462</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/http/client.py?line=462'>463</a>\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/http/client.py?line=463'>464</a>\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[1;32m--> <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/http/client.py?line=464'>465</a>\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/http/client.py?line=465'>466</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/http/client.py?line=466'>467</a>\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/http/client.py?line=467'>468</a>\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/http/client.py?line=468'>469</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/socket.py?line=702'>703</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/socket.py?line=703'>704</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/socket.py?line=704'>705</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/socket.py?line=705'>706</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/socket.py?line=706'>707</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1273\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1268'>1269</a>\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1269'>1270</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1270'>1271</a>\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1271'>1272</a>\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1272'>1273</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1273'>1274</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1274'>1275</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1129\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1126'>1127</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1127'>1128</a>\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1128'>1129</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1129'>1130</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/spaceastonomy/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1130'>1131</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "cats = ['alt.atheism', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=cats)\n",
    "\n",
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "# this calculates a vector of term frequencies for \n",
    "# each document\n",
    "vect = CountVectorizer()\n",
    "\n",
    "# this normalizes each term frequency by the \n",
    "# number of documents having that term\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "# this is a linear SVM classifier\n",
    "clf = LinearSVC()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect',vect),\n",
    "    ('tfidf',tfidf),\n",
    "    ('clf',clf)\n",
    "])\n",
    "\n",
    "scores = cross_val_score(pipeline,X_train,y_train,cv=3,scoring='f1_micro')\n",
    "\n",
    "scores\n",
    "\n",
    "scores.mean()\n",
    "\n",
    "# now train and predict test instances\n",
    "pipeline.fit(X_train,y_train)\n",
    "y_preds = pipeline.predict(X_test)\n",
    "\n",
    "# calculate f1\n",
    "f1_score(y_test, y_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer=load_diabetes()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly=PolynomialFeatures(degree=2,include_bias=False)\n",
    "base_model=LinearRegression()\n",
    "pipe=Pipeline([('poly',poly),\n",
    "               ('base_model',base_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('poly', PolynomialFeatures(include_bias=False)),\n",
       "                ('base_model', LinearRegression())])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 평가 :  0.6374898647317722\n",
      "테스트 평가 :  0.2620821087031828\n"
     ]
    }
   ],
   "source": [
    "print('학습 평가 : ', pipe.score(X_train, y_train))\n",
    "print('테스트 평가 : ', pipe.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ddbee94c2ce3b61c3b1774ea67d55f2fdae8c29319837f6f09ba2209f9564fc6"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
